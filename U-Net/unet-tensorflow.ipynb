{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "def load_data(images_folder, masks_folder):\n",
    "    image_files = os.listdir(images_folder)\n",
    "    mask_files = os.listdir(masks_folder)\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(images_folder, img_file)\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        images.append(img)\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask_path = os.path.join(masks_folder, mask_file)\n",
    "        mask = np.array(Image.open(mask_path).convert('L'))\n",
    "        masks.append(mask)\n",
    "\n",
    "        # mask_file = img_file.split('.')[0] + '_mask.png'  # Assuming mask files are named similarly\n",
    "        # mask_path = os.path.join(masks_folder, mask_file)\n",
    "        # mask = np.array(Image.open(mask_path).convert('L'))  # Convert to grayscale\n",
    "        # masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Step 2: Preprocess the Data\n",
    "def preprocess_data(images, masks):\n",
    "    # Resize images and masks, normalize pixel values, and prepare the data for training\n",
    "    images = images.astype('float32') / 255.0\n",
    "    masks = masks.astype('float32') / 255.0  # Assuming masks are in [0, 255] range\n",
    "    return images, masks\n",
    "\n",
    "# Step 3: Define the U-Net Model\n",
    "def unet(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Define the U-Net architecture\n",
    "    # Contracting Path\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Expansive Path\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    conv4_resized = tf.image.resize(conv4, tf.shape(up6)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up6 = layers.concatenate([up6, conv4_resized], axis=3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    conv3_resized = tf.image.resize(conv3, tf.shape(up7)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up7 = layers.concatenate([up7, conv3_resized], axis=3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    conv2_resized = tf.image.resize(conv2, tf.shape(up8)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up8 = layers.concatenate([up8, conv2_resized], axis=3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    conv1_resized = tf.image.resize(conv1, tf.shape(up9)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up9 = layers.concatenate([up9, conv1_resized], axis=3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = layers.Conv2D(3, 1, activation='softmax')(conv9)  # Assuming 3 output classes\n",
    "    print(\"final layer\", outputs.shape)\n",
    "\n",
    "    original_shape_outputs = tf.image.resize(outputs, input_shape[:2])\n",
    "    print(\"final layer modified layer\", original_shape_outputs.shape)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs=inputs, outputs=original_shape_outputs)\n",
    "    return model\n",
    "\n",
    "# Step 4: Compile the Model\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the Model\n",
    "def train_model(model, images, masks, epochs=10, batch_size=32, validation_split=0.2):\n",
    "    model.fit(images, masks, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the paths to your dataset folders\n",
    "    images_folder = '/content/Program/U-Net/train/images'\n",
    "    masks_folder = '/content/Program/U-Net/train/masks'\n",
    "\n",
    "    # Load dataset\n",
    "    images, masks = load_data(images_folder, masks_folder)\n",
    "    print(\"shape images\", images.shape)\n",
    "    print(\"shape masks\", masks.shape)\n",
    "\n",
    "    # Preprocess the data\n",
    "    images, masks = preprocess_data(images, masks)\n",
    "    print(\"~shape images\", images.shape)\n",
    "    print(\"~shape masks\", masks.shape)\n",
    "\n",
    "    # Define input shape\n",
    "    input_shape = images[0].shape\n",
    "    print(\"shape masks\", images[0].shape)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = unet(input_shape)\n",
    "\n",
    "    # Compile the model\n",
    "    compile_model(model)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, images, masks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
