{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape images (59, 200, 101, 3)\n",
      "shape masks (59, 200, 101)\n",
      "~shape images (59, 200, 101, 3)\n",
      "~shape masks (59, 200, 101)\n",
      "shape masks (200, 101, 3)\n",
      "final layer (None, 192, 96, 3)\n",
      "final layer modified layer (None, 200, 101, 3)\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 658ms/step - loss: nan - accuracy: 0.2622 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 328ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 327ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 323ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 319ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 318ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 318ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 314ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 315ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 319ms/step - loss: nan - accuracy: 0.8000 - val_loss: nan - val_accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "def load_data(images_folder, masks_folder):\n",
    "    image_files = os.listdir(images_folder)\n",
    "    mask_files = os.listdir(masks_folder)\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(images_folder, img_file)\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        images.append(img)\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask_path = os.path.join(masks_folder, mask_file)\n",
    "        mask = np.array(Image.open(mask_path).convert('L'))\n",
    "        masks.append(mask)\n",
    "\n",
    "        # mask_file = img_file.split('.')[0] + '_mask.png'  # Assuming mask files are named similarly\n",
    "        # mask_path = os.path.join(masks_folder, mask_file)\n",
    "        # mask = np.array(Image.open(mask_path).convert('L'))  # Convert to grayscale\n",
    "        # masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Step 2: Preprocess the Data\n",
    "def preprocess_data(images, masks):\n",
    "    # Resize images and masks, normalize pixel values, and prepare the data for training\n",
    "    images = images.astype('float32') / 255.0\n",
    "    masks = masks.astype('float32') / 255.0  # Assuming masks are in [0, 255] range\n",
    "    return images, masks\n",
    "\n",
    "# Step 3: Define the U-Net Model\n",
    "def unet(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Define the U-Net architecture\n",
    "    # Contracting Path\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Expansive Path\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    conv4_resized = tf.image.resize(conv4, tf.shape(up6)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up6 = layers.concatenate([up6, conv4_resized], axis=3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    conv3_resized = tf.image.resize(conv3, tf.shape(up7)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up7 = layers.concatenate([up7, conv3_resized], axis=3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    conv2_resized = tf.image.resize(conv2, tf.shape(up8)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up8 = layers.concatenate([up8, conv2_resized], axis=3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    conv1_resized = tf.image.resize(conv1, tf.shape(up9)[1:3], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    up9 = layers.concatenate([up9, conv1_resized], axis=3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = layers.Conv2D(3, 1, activation='softmax')(conv9)  # Assuming 3 output classes\n",
    "    print(\"final layer\", outputs.shape)\n",
    "\n",
    "    original_shape_outputs = tf.image.resize(outputs, input_shape[:2])\n",
    "    print(\"final layer modified layer\", original_shape_outputs.shape)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs=inputs, outputs=original_shape_outputs)\n",
    "    return model\n",
    "\n",
    "# Step 4: Compile the Model\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the Model\n",
    "def train_model(model, images, masks, epochs=10, batch_size=32, validation_split=0.2):\n",
    "    model.fit(images, masks, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the paths to your dataset folders\n",
    "    images_folder = r'C:\\Users\\Admin\\Documents\\Naufal\\Program\\U-Net\\train\\images'\n",
    "    masks_folder = r'C:\\Users\\Admin\\Documents\\Naufal\\Program\\U-Net\\train\\masks'\n",
    "\n",
    "    # Load dataset\n",
    "    images, masks = load_data(images_folder, masks_folder)\n",
    "    print(\"shape images\", images.shape)\n",
    "    print(\"shape masks\", masks.shape)\n",
    "\n",
    "    # Preprocess the data\n",
    "    images, masks = preprocess_data(images, masks)\n",
    "    print(\"~shape images\", images.shape)\n",
    "    print(\"~shape masks\", masks.shape)\n",
    "\n",
    "    # Define input shape\n",
    "    input_shape = images[0].shape\n",
    "    print(\"shape masks\", images[0].shape)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = unet(input_shape)\n",
    "\n",
    "    # Compile the model\n",
    "    compile_model(model)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image file using OpenCV\n",
    "image = cv2.imread(r'C:\\Users\\Admin\\Documents\\Naufal\\Program\\U-Net\\train\\masks\\3_img_png.rf.86c077a0fb6d191e5dc359eeaff17904.jpg')\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Now you can work with the image data as a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value 0: Count 46416\n",
      "Value 1: Count 627\n",
      "Value 2: Count 375\n",
      "Value 3: Count 210\n",
      "Value 4: Count 54\n",
      "Value 5: Count 33\n",
      "Value 6: Count 6\n",
      "Value 7: Count 3\n",
      "Value 8: Count 3\n",
      "Value 10: Count 3\n",
      "Value 11: Count 9\n",
      "Value 12: Count 3\n",
      "Value 13: Count 3\n",
      "Value 14: Count 3\n",
      "Value 15: Count 3\n",
      "Value 20: Count 6\n",
      "Value 21: Count 3\n",
      "Value 26: Count 3\n",
      "Value 30: Count 9\n",
      "Value 32: Count 6\n",
      "Value 35: Count 3\n",
      "Value 36: Count 3\n",
      "Value 37: Count 12\n",
      "Value 39: Count 15\n",
      "Value 43: Count 3\n",
      "Value 45: Count 6\n",
      "Value 48: Count 3\n",
      "Value 51: Count 3\n",
      "Value 54: Count 3\n",
      "Value 55: Count 3\n",
      "Value 59: Count 3\n",
      "Value 63: Count 6\n",
      "Value 64: Count 3\n",
      "Value 65: Count 3\n",
      "Value 68: Count 3\n",
      "Value 69: Count 3\n",
      "Value 70: Count 3\n",
      "Value 74: Count 3\n",
      "Value 76: Count 3\n",
      "Value 89: Count 3\n",
      "Value 90: Count 3\n",
      "Value 91: Count 6\n",
      "Value 92: Count 6\n",
      "Value 93: Count 6\n",
      "Value 94: Count 6\n",
      "Value 95: Count 12\n",
      "Value 96: Count 3\n",
      "Value 97: Count 6\n",
      "Value 101: Count 6\n",
      "Value 105: Count 3\n",
      "Value 106: Count 3\n",
      "Value 108: Count 3\n",
      "Value 109: Count 6\n",
      "Value 122: Count 9\n",
      "Value 123: Count 33\n",
      "Value 124: Count 87\n",
      "Value 125: Count 222\n",
      "Value 126: Count 498\n",
      "Value 127: Count 672\n",
      "Value 128: Count 9273\n",
      "Value 129: Count 732\n",
      "Value 130: Count 504\n",
      "Value 131: Count 255\n",
      "Value 132: Count 84\n",
      "Value 133: Count 9\n",
      "Value 134: Count 6\n",
      "Value 138: Count 3\n",
      "Value 149: Count 3\n",
      "Value 170: Count 3\n",
      "Value 172: Count 3\n",
      "Value 183: Count 3\n",
      "Value 194: Count 3\n",
      "Value 204: Count 3\n",
      "Value 237: Count 3\n",
      "Value 244: Count 3\n",
      "Value 250: Count 6\n",
      "Value 251: Count 15\n",
      "Value 252: Count 15\n",
      "Value 253: Count 36\n",
      "Value 254: Count 36\n",
      "Value 255: Count 147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_values, counts = np.unique(image_array, return_counts=True)\n",
    "\n",
    "# Print the counts for each unique value\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value}: Count {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
